# openai-mcp-server/pyproject.toml

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "openai-mcp-server"
version = "0.1.3"
description = "An MCP server for interacting with OpenAI APIs (GPT, DALL-E, etc.)"
authors = [
    { name = "ParisNeo", email = "parisneoai@gmail.com" },
]
license = "MIT"
readme = "README.md"
requires-python = ">=3.9" # OpenAI library and FastMCP benefit from modern Python
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "mcp>=0.6.0", # Or your specific required version of MCP SDK
    "openai>=1.0.0", # Use the new OpenAI SDK version
    "python-dotenv>=0.20.0",
    "uvicorn>=0.20.0", # For running FastMCP if not using mcp cli's stdio directly
    "ascii-colors>=0.5.5", # For nice console output
]

[project.scripts]
# This defines the command that `uvx openai-mcp-server` will effectively run
# (or `uv run openai-mcp-server` from within the project directory)
openai-mcp-server = "openai_mcp_server.server:main_cli"

[project.urls]
Homepage = "https://github.com/PArisNeoMCPServers/openai-mcp-server" # Replace
Repository = "https://github.com/PArisNeoMCPServers/openai-mcp-server" # Replace

# Optional: For Hatchling specific build configurations if needed
# [tool.hatch.build.targets.wheel]
# packages = ["openai_mcp_server"]